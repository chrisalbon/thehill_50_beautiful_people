{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create A Master List Of URLS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urls_2011 = []\n",
    "    \n",
    "for person in list(range(0,50)):\n",
    "    base_url = 'http://thehill.com/capital-living/173451-50-most-beautiful-people-2011-washington-congress-capitol?page=0%2C'\n",
    "    full_url = base_url+str(person)\n",
    "    urls_2011.append(full_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urls_2012 = []\n",
    "    \n",
    "for person in list(range(0,50)):\n",
    "    base_url = 'http://thehill.com/capital-living/cover-stories/239791-the-hills-50-most-beautiful-people-2012?page=0%2C'\n",
    "    full_url = base_url+str(person)\n",
    "    urls_2012.append(full_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urls_2013 = []\n",
    "    \n",
    "for person in list(range(1,51)):\n",
    "    base_url = 'http://thehill.com/50-most-beautiful-2013/index.php?n='\n",
    "    full_url = base_url+str(person)\n",
    "    urls_2013.append(full_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'http://thehill.com/50-most-beautiful/2014'\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.content)\n",
    "\n",
    "urls_2014 = []\n",
    "\n",
    "for cell in soup.table.find_all('a'):\n",
    "    base_url = 'http://thehill.com/'\n",
    "    person_url = str(cell.get('href'))\n",
    "    full_url = base_url+person_url\n",
    "    urls_2014.append(full_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urls_2015 = [\n",
    "    'http://thehill.com/50-most-beautiful/2015/249284-taylor-weeks',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249286-sarindee-wickramasuriya',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249294-mike-sacks',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249310-caitlin-sause',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249312-juan-mccullum',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249315-sen-martin-heinrich',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249316-cassie-roper',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249274-jon-adams',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249384-michelle-obama',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249319-shannon-bream',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249320-michelle-rutter',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249323-chase-jennings',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249326-eric-bolden',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249580-rep-tulsi-gabbard',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249347-matt-dornic',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249349-teresa-davis',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249368-carri-twigg',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249582-majida-mourad',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249369-rep-seth-moulton',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249385-jinyoung-lee-englund',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249437-chaffon-davis',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249444-chris-jansing',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249445-yusuf-parray',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249449-kristin-strobel',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249465-carl-ray',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249468-audrey-pfund',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249474-diana-oo',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249476-sophia-anwar',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249482-barack-obama',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249486-sara-neagu',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249488-mone-ross',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249490-sheila-nix',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249491-rep-norma-torres',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249493-alex-rosen',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249528-marsha-brogdon',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249530-christopher-gindy-gindlesperger',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249533-lemia-jenkins',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249536-kimberly-willingham',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249542-margaret-brennan',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249545-jack-lincoln',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249547-ola-williams',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249550-kori-schulman',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249583-sen-marco-rubio',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249554-courtney-parella',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249562-xavier-underwood',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249564-michelle-fields',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249566-tim-torres',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249569-paul-vitrano',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249572-jillian-neville',\n",
    "    'http://thehill.com/50-most-beautiful/2015/249575-kevin-lefeber',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Each Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name = []\n",
    "hometown = []\n",
    "homestate = []\n",
    "age = []\n",
    "relationship = []\n",
    "party = []\n",
    "year = []\n",
    "\n",
    "for url in urls_2011:\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    \n",
    "    # Year\n",
    "    year.append(2011)\n",
    "    \n",
    "    # Get Name (Can't)\n",
    "    name.append(np.nan)\n",
    "    \n",
    "    # Get Age\n",
    "    age_n = soup.find(text=re.compile('Age:'))\n",
    "    try:\n",
    "        age_n = age_n.split(': ')[1]\n",
    "    except:\n",
    "        age_n = np.nan\n",
    "    age.append(age_n)\n",
    "    \n",
    "    # Get Hometown and Homestate\n",
    "    home_n = soup.find(text=re.compile('Hometown:'))\n",
    "    home_n = home_n.split(': ')[1]\n",
    "    hometown_n = home_n.split(', ')[0]\n",
    "    try:\n",
    "        homestate_n = home_n.split(', ')[1]\n",
    "    except:\n",
    "        homestate_n = np.nan\n",
    "    hometown.append(hometown_n)\n",
    "    homestate.append(homestate_n)\n",
    "    \n",
    "    # Get relationship status\n",
    "    relationship_n = soup.find(text=re.compile('Relationship status: '))\n",
    "    try:\n",
    "        relationship_n = relationship_n.split(': ')[1]\n",
    "    except:\n",
    "        relationship_n = np.nan\n",
    "    relationship.append(relationship_n)\n",
    "    \n",
    "    # Get party affiliation\n",
    "    party_n = soup.find(text=re.compile('Political party: '))\n",
    "    try:\n",
    "        party_n = party_n.split(': ')[1]\n",
    "    except:\n",
    "        party_n = np.nan\n",
    "    party.append(party_n)\n",
    "    \n",
    "    # Get party affiliation\n",
    "    div_class = soup.findAll(\"div\", { \"class\" : \"field-item\" })\n",
    "    all_p_for_page = div_class[1].findAll(\"p\")\n",
    "    \n",
    "lists = {'Name': name,\n",
    "         'Year': year,\n",
    "         'Hometown': hometown,\n",
    "         'Homestate': homestate,\n",
    "         'Age': age,\n",
    "         'Relationship': relationship,\n",
    "         'Party': party,\n",
    "         'URL': urls_2011}\n",
    "\n",
    "df_2011 = pd.DataFrame(lists, columns = ['Name', 'Year', 'Hometown', 'Homestate', 'Age', 'Relationship', 'Party', 'URL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = []\n",
    "hometown = []\n",
    "homestate = []\n",
    "age = []\n",
    "relationship = []\n",
    "party = []\n",
    "year = []\n",
    "\n",
    "for url in urls_2012:\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    \n",
    "    # Year\n",
    "    year.append(2012)\n",
    "    \n",
    "    # Get Name (Can't)\n",
    "    name.append(np.nan)\n",
    "    \n",
    "    # Get Age\n",
    "    age_n = soup.find(text=re.compile('Age:'))\n",
    "    try:\n",
    "        age_n = age_n.split(': ')[1]\n",
    "    except:\n",
    "        age_n = np.nan\n",
    "    age.append(age_n)\n",
    "    \n",
    "    # Get Hometown and Homestate\n",
    "    home_n = soup.find(text=re.compile('Hometown:'))\n",
    "    home_n = home_n.split(': ')[1]\n",
    "    hometown_n = home_n.split(', ')[0]\n",
    "    try:\n",
    "        homestate_n = home_n.split(', ')[1]\n",
    "    except:\n",
    "        homestate_n = np.nan\n",
    "    hometown.append(hometown_n)\n",
    "    homestate.append(homestate_n)\n",
    "    \n",
    "    # Get relationship status\n",
    "    relationship_n = soup.find(text=re.compile('Relationship status: '))\n",
    "    try:\n",
    "        relationship_n = relationship_n.split(': ')[1]\n",
    "    except:\n",
    "        relationship_n = np.nan\n",
    "    relationship.append(relationship_n)\n",
    "    \n",
    "    # Get party affiliation\n",
    "    party_n = soup.find(text=re.compile('Political party: '))\n",
    "    try:\n",
    "        party_n = party_n.split(': ')[1]\n",
    "    except:\n",
    "        party_n = np.nan\n",
    "    party.append(party_n)\n",
    "    \n",
    "    # Get party affiliation\n",
    "    div_class = soup.findAll(\"div\", { \"class\" : \"field-item\" })\n",
    "    all_p_for_page = div_class[1].findAll(\"p\")\n",
    "    \n",
    "lists = {'Name': name,\n",
    "         'Year': year,\n",
    "         'Hometown': hometown,\n",
    "         'Homestate': homestate,\n",
    "         'Age': age,\n",
    "         'Relationship': relationship,\n",
    "         'Party': party,\n",
    "         'URL': urls_2012}\n",
    "\n",
    "df_2012 = pd.DataFrame(lists, columns = ['Name', 'Year', 'Hometown', 'Homestate', 'Age', 'Relationship', 'Party', 'URL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name = []\n",
    "hometown = []\n",
    "homestate = []\n",
    "age = []\n",
    "relationship = []\n",
    "party = []\n",
    "year = []\n",
    "\n",
    "for url in urls_2013:\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    \n",
    "    # Year\n",
    "    year.append(2013)\n",
    "    \n",
    "    # Get Name (Can't)\n",
    "    name.append(np.nan)\n",
    "    \n",
    "    # Get Age\n",
    "    age_n = soup.find(text=re.compile('Age:'))\n",
    "    try:\n",
    "        age_n = age_n.split(': ')[1]\n",
    "    except:\n",
    "        age_n = np.nan\n",
    "    age.append(age_n)\n",
    "    \n",
    "    # Get Hometown and Homestate\n",
    "    home_n = soup.find(text=re.compile('Hometown:'))\n",
    "    home_n = home_n.split(': ')[1]\n",
    "    hometown_n = home_n.split(', ')[0]\n",
    "    try:\n",
    "        homestate_n = home_n.split(', ')[1]\n",
    "    except:\n",
    "        homestate_n = np.nan\n",
    "    hometown.append(hometown_n)\n",
    "    homestate.append(homestate_n)\n",
    "    \n",
    "    # Get relationship status\n",
    "    relationship_n = soup.find(text=re.compile('Relationship status: '))\n",
    "    try:\n",
    "        relationship_n = relationship_n.split(': ')[1]\n",
    "    except:\n",
    "        relationship_n = np.nan\n",
    "    relationship.append(relationship_n)\n",
    "    \n",
    "    # Get party affiliation\n",
    "    party_n = soup.find(text=re.compile('Political party: '))\n",
    "    try:\n",
    "        party_n = party_n.split(': ')[1]\n",
    "    except:\n",
    "        party_n = np.nan\n",
    "    party.append(party_n)\n",
    "    \n",
    "lists = {'Name': name,\n",
    "         'Year': year,\n",
    "         'Hometown': hometown,\n",
    "         'Homestate': homestate,\n",
    "         'Age': age,\n",
    "         'Relationship': relationship,\n",
    "         'Party': party,\n",
    "         'URL': urls_2013}\n",
    "\n",
    "df_2013 = pd.DataFrame(lists, columns = ['Name', 'Year', 'Hometown', 'Homestate', 'Age', 'Relationship', 'Party', 'URL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name = []\n",
    "hometown = []\n",
    "homestate = []\n",
    "age = []\n",
    "relationship = []\n",
    "party = []\n",
    "year = []\n",
    "\n",
    "for url in urls_2014:\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    \n",
    "    # Year\n",
    "    year.append(2014)\n",
    "    \n",
    "    # Get Name\n",
    "    name_n = soup.find(\"div\", { \"class\" : \"field-item\" }).img['title']\n",
    "    name.append(name_n)\n",
    "    \n",
    "    # Get Age\n",
    "    try:\n",
    "        age_n = soup.find(text=re.compile('Age:')).next.string\n",
    "    except:\n",
    "        age_n = np.nan\n",
    "    age.append(age_n)\n",
    "    \n",
    "    # Get Hometown and Homestate\n",
    "    try:\n",
    "        home_n = soup.find(text=re.compile('Hometown:')).next.string\n",
    "    except:\n",
    "        home_n = np.nan\n",
    "    try:\n",
    "        hometown_n = home_n.split(', ')[0]\n",
    "    except:\n",
    "        hometown_n = np.nan\n",
    "    try:\n",
    "        homestate_n = home_n.split(', ')[1]\n",
    "    except:\n",
    "        homestate_n = np.nan\n",
    "    hometown.append(hometown_n)\n",
    "    homestate.append(homestate_n)\n",
    "    \n",
    "    # Get relationship status\n",
    "    try:\n",
    "        relationship_n = soup.find(text=re.compile('Relationship Status:')).next.string\n",
    "    except:\n",
    "        relationship_n = np.nan\n",
    "    relationship.append(relationship_n)\n",
    "    \n",
    "    # Get party affiliation\n",
    "    try:\n",
    "        party_n = soup.find(text=re.compile('Party Affiliation:')).next.string\n",
    "    except:\n",
    "        party_n = np.nan\n",
    "    party.append(party_n)\n",
    "    \n",
    "lists = {'Name': name,\n",
    "         'Year': year,\n",
    "         'Hometown': hometown,\n",
    "         'Homestate': homestate,\n",
    "         'Age': age,\n",
    "         'Relationship': relationship,\n",
    "         'Party': party,\n",
    "         'URL': urls_2014}\n",
    "\n",
    "df_2014 = pd.DataFrame(lists, columns = ['Name', 'Year', 'Hometown', 'Homestate', 'Age', 'Relationship', 'Party', 'URL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = []\n",
    "hometown = []\n",
    "homestate = []\n",
    "age = []\n",
    "relationship = []\n",
    "party = []\n",
    "year = []\n",
    "\n",
    "for url in urls_2015:\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    \n",
    "    # Year\n",
    "    year.append(2015)\n",
    "    \n",
    "    # Get Name\n",
    "    name_n = soup.find(\"div\", { \"class\" : \"field-item\" }).img['title']\n",
    "    name.append(name_n)\n",
    "    \n",
    "    # Get Age\n",
    "    try:\n",
    "        age_n = soup.find(text=re.compile('Age:')).next.string\n",
    "    except:\n",
    "        age_n = np.nan\n",
    "    age.append(age_n)\n",
    "    \n",
    "    # Get Hometown and Homestate\n",
    "    try:\n",
    "        home_n = soup.find(text=re.compile('Hometown:')).next.string\n",
    "    except:\n",
    "        home_n = np.nan\n",
    "    try:\n",
    "        hometown_n = home_n.split(', ')[0]\n",
    "    except:\n",
    "        hometown_n = np.nan\n",
    "    try:\n",
    "        homestate_n = home_n.split(', ')[1]\n",
    "    except:\n",
    "        homestate_n = np.nan\n",
    "    hometown.append(hometown_n)\n",
    "    homestate.append(homestate_n)\n",
    "    \n",
    "    # Get relationship status\n",
    "    try:\n",
    "        relationship_n = soup.find(text=re.compile('Relationship Status:')).next.string\n",
    "    except:\n",
    "        relationship_n = np.nan\n",
    "    relationship.append(relationship_n)\n",
    "    \n",
    "    # Get party affiliation\n",
    "    try:\n",
    "        party_n = soup.find(text=re.compile('Party Affiliation:')).next.string\n",
    "    except:\n",
    "        party_n = np.nan\n",
    "    party.append(party_n)\n",
    "    \n",
    "lists = {'Name': name,\n",
    "         'Year': year,\n",
    "         'Hometown': hometown,\n",
    "         'Homestate': homestate,\n",
    "         'Age': age,\n",
    "         'Relationship': relationship,\n",
    "         'Party': party,\n",
    "         'URL': urls_2015}\n",
    "\n",
    "df_2015 = pd.DataFrame(lists, columns = ['Name', 'Year', 'Hometown', 'Homestate', 'Age', 'Relationship', 'Party', 'URL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_2011,df_2012,df_2013,df_2014,df_2015])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "homestate_standardization = {'Iowa' : 'IA',\n",
    "'Tenn.' : 'TN', \n",
    " 'N.Y.' : 'NY', \n",
    " 'S.C.' : 'SC',\n",
    " 'Ill.' : 'IL',\n",
    " 'Wash.' : 'WA',\n",
    " 'Va.': 'VA', \n",
    " 'S.D.' : 'SD',\n",
    " 'England' : 'England', \n",
    " 'Ind.' : 'IN', \n",
    " 'N.J.' : 'NJ', \n",
    " 'Idaho' : 'ID', \n",
    " 'South Africa' : 'South Africa',\n",
    " 'Mo.' : 'MO',\n",
    " 'Md.' : 'MD',\n",
    " 'Fla.' : 'FL',\n",
    " 'Puerto Rico' : 'PR',\n",
    " 'U.S. Virgin Islands' : 'VI',\n",
    " 'Minn.' : 'MN',\n",
    " 'Ohio' : 'OH',\n",
    " 'Ariz.' : 'AZ',\n",
    " 'Alaska' : 'AK',\n",
    " 'N.C.' : 'NC',\n",
    " 'Wyo.\\xa0' : 'WY',\n",
    " 'Mass.' : 'MA',\n",
    " 'Albania' : 'Albania',\n",
    " 'Wis.' : 'WI',\n",
    " 'Okla.' : 'OK',\n",
    " 'N.H.' : 'NH',\n",
    " 'Calif.' : 'CA',\n",
    " 'Conn.' : 'CT',\n",
    " 'Miss.' : 'MS',\n",
    " 'Pa.' : 'PA',\n",
    " 'Ala.' : 'AL',\n",
    " 'Maine' : 'MA',\n",
    " 'Texas' : 'TX',\n",
    " 'Wis.\\xa0' : 'WI',\n",
    " 'Ghana' : 'Ghana',\n",
    " 'Ky.' : 'KY',\n",
    " 'Calif.\\xa0' : 'CA',\n",
    " 'Mich.' : 'MI',\n",
    " 'Hawaii' : 'HI',\n",
    " 'Calif.; Aviano' : 'CA',\n",
    " 'N.M.' : 'NM',\n",
    " 'R.I.' : 'RI',\n",
    " 'D.C.' : 'DC',\n",
    " 'Ga.' : 'GA',\n",
    " 'Ark.' : 'AR',\n",
    " 'Nevada' : 'NV',\n",
    " 'Md./Puerto Rico' : 'MD',\n",
    " 'Mo.\\u2028' : 'MO',\n",
    " 'Utah' : 'UT',\n",
    " 'Va. ' : 'VA',\n",
    " 'Israel' : 'Israel',\n",
    " 'Ore.' : 'OR', \n",
    " 'La.' : 'LA', \n",
    " 'Burma' : 'Burma'\n",
    "}\n",
    "\n",
    "df['Homestate'] = df['Homestate'].replace(homestate_standardization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "relationship_standardization = {'Single' : 'Single', \n",
    "                                'In a relationship' : 'In a relationship',\n",
    "                                'Girlfriend (Remy, his college sweetheart)' : 'In a relationship', \n",
    "                                'Married' : 'Married',\n",
    "                                '“Mingling — not single, not in a relationship.”' : 'Other',\n",
    "                                '“Not single and very happy”' : 'In a relationship',\n",
    "                                'Girlfriend (“She says I’m off limits.”)' : 'In a relationship', \n",
    "                                'Recently engaged\\xa0' : 'Engaged',\n",
    "                                'Dating' : 'In a relationship', \n",
    "                                '“In a serious relationship, and happily so.”' : 'In a relationship',\n",
    "                                'Boyfriend' : 'In a relationship', \n",
    "                                'Has a boyfriend' : 'In a relationship', \n",
    "                                'Has a girlfriend' : 'In a relationship', \n",
    "                                'Engaged' : 'Engaged',\n",
    "                                'Single\\xa0' : 'Single', \n",
    "                                'Declined to specify' : np.nan, \n",
    "                                'In a long-term relationship' : 'In a relationship',\n",
    "                                'Girlfriend' : 'In a relationship', \n",
    "                                'In a relationship\\xa0' : 'In a relationship', \n",
    "                                '“Happily taken”' : 'In a relationship', \n",
    "                                '“Taken”' : 'In a relationship',\n",
    "                                'Private' : np.nan, \n",
    "                                'Widowed' : 'Widowed', \n",
    "                                'Single ' : 'Single', \n",
    "                                'In a Relationship' : 'In a relationship', \n",
    "                                'Spoken for' : 'In a relationship',\n",
    "                                '“Evolving”' : 'In a relationship', \n",
    "                                'Longtime girlfriend ' : 'In a relationship', \n",
    "                                'Single and dating' : 'Single',\n",
    "                                'Live-in boyfriend' : 'In a relationship', \n",
    "                                'In a relationship ' : 'In a relationship',\n",
    "                                'Girlfriend of four months ' : 'In a relationship', \n",
    "                                'Boyfriend of three years' : 'In a relationship',\n",
    "                                'Unmarried' : 'Single', \n",
    "                                'Declined to disclose' : np.nan, \n",
    "                                'Seeing someone' : 'In a relationship',\n",
    "                                '“Unmarried”' : 'Single', \n",
    "                                'Declined to answer' : np.nan, \n",
    "                                '“Happily married”' : 'Married'}\n",
    "\n",
    "df['Relationship'] = df['Relationship'].replace(relationship_standardization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "party_standardization = {\n",
    "    'Republican' : 'Conservative', \n",
    "    'Nonpartisan' : 'Moderate', \n",
    "    'Democratic' : 'Liberal', \n",
    "    '“Not Republican”' : 'Liberal',\n",
    "    'Democratic\\xa0' : 'Liberal',\n",
    "    'Centrist' : 'Moderate',\n",
    "    'Independent' : 'Moderate',\n",
    "    'GOProud Conservative' : 'Conservative',\n",
    "    'Democrat' : 'Liberal',\n",
    "    'Libertarian' : 'Conservative',\n",
    "    'Republican\\xa0' : 'Conservative',\n",
    "    '“Moderate”' : 'Moderate',\n",
    "    'Agnostic' : 'Moderate',\n",
    "    'Rather not say' : np.nan,\n",
    "    'Non-affiliated' : 'Moderate',\n",
    "    'None' : np.nan,\n",
    "    'Conservative' : 'Conservative',\n",
    "    'Unaffiliated' : 'Moderate',\n",
    "    'Democratic ' : 'Liberal',\n",
    "    '“Split-ticket voter”' : 'Moderate',\n",
    "    '“Conservative”' : 'Conservative',\n",
    "    '“Proud Democrat”' : 'Liberal',\n",
    "    '“Advocate”' : np.nan,\n",
    "}\n",
    "\n",
    "df['Party'] = df['Party'].replace(party_standardization)\n",
    "\n",
    "df = df.rename(columns={'Party': 'Ideology'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age_cleaning = {\n",
    "'45\\xa0':'45',\n",
    "'24\\xa0':'24',\n",
    "'23\\xa0':'23',\n",
    "'30\\xa0':'30',\n",
    "'Born “in the early to mid-1970s”':np.nan,\n",
    "'28\\xa0':'28'}\n",
    "\n",
    "df[\"Age\"] = df[\"Age\"].convert_objects(convert_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"clean_data/scraped_data_clean_no_handcoding.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
